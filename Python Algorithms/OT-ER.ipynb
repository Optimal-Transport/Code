{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropic Regularisation to solve Discrete Optimal Transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "This notebook we aim at solving DOT instances using modern optimisation algorithms that outperform the simplex method. To do this we will use the Entropic Regularisation framework. \n",
    "    \n",
    "The notebook is divided in three parts. First, Condat's projection into the ℓ<sub>1</sub> ball algorithm is implemented. Second, the algorithm is used to find feasible solutions of DOT. Finally, the Entropic Regularisation algorithm is tested. The results are automatically stored with an unique identifier and some performance plots are presented.\n",
    "</div>\n",
    "\n",
    "* Laurent Condat. <i>Fast projection onto the simplex and the ℓ<sub>1</sub> ball</i>. Math. Program. 158, 575–585 (2016). [https://doi.org/10.1007/s10107-015-0946-6](https://doi.org/10.1007/s10107-015-0946-6). _Also available at_ [https://hal.archives-ouvertes.fr/hal-01056171v2](https://hal.archives-ouvertes.fr/hal-01056171v2).\n",
    "\n",
    "\n",
    "\n",
    "* M. Cuturi. <i> Sinkhorn Distances : Lightspeed Computation of Optimal Transport </i>. Advances in Neural Information Processing Systems (NIPS) 26, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Packages\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Particular functions\n",
    "from numpy import zeros, zeros_like, allclose, where, ones, inf, absolute, linspace\n",
    "from numpy.random import default_rng as rng\n",
    "from numba import jit\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create subroutines that will be iteratively used in the main algorithm. ```[Include only the ones needed for each algorithm]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Projection onto the simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we provide an implementation of Condat's algorithm. The main steps are precompiled using the Just-in-time package ```numba``` to gain a speed-up. To get the best computing times, the resulting jitted function has to be run at least once before an actual iterative test. For the tests, we will project a random vector $y$ of size $N$ with $y_n \\sim \\mathcal{U}(-1,2)$ for all $n\\in \\{1,\\ldots,N\\}$ and a 20% mask of zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); vertical-align: middle; padding:5px 0; padding-left: 40px;\">\n",
    "<h2 style=\"color: #5e9ca0;\">Condat's Algorithm</h2>\n",
    "<ol>\n",
    "<li>Set $v:= (y_1)$, $u$ as an empty list, $\\rho:= y_1 - a$.</li>\n",
    "<li>For $n \\in \\{2,\\ldots, N\\}$, do\n",
    "<ol>\n",
    "<li>If $y_n > \\rho$\n",
    "<ol>\n",
    "<li>Set $\\rho := \\rho + (y_n - \\rho)/(|v|+1)$.</li>\n",
    "<li>If $\\rho > y_n - a$, add $y_n$ to $v$.</li>\n",
    "<li>Else, add $v$ to $u$, set $v = (y_n)$, $\\rho = y_n -a$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>If $u$ is not empty, for every element $y$ of $u$, do\n",
    "<ol>\n",
    "<li>If $y > \\rho$, add $y$ to $v$ and set $\\rho := \\rho + (y-\\rho)/|v|$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>Do, while $|v|$ changes,\n",
    "<ol>\n",
    "<li>For every element $y$ of $v$ do\n",
    "<ol>\n",
    "<li>If $y\\leq \\rho$, remove $y$ from $v$ and set $\\rho := \\rho + (\\rho - y)/|v|$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>Set $\\tau := \\rho$, $K = |v|$.</li>\n",
    "<li>For $n \\in \\{1,\\ldots,N\\}$, set $x_n := \\max \\{y_n - \\tau, 0\\}$.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "y = rng(0).uniform(-1,2,N);    y = where(rng(0).binomial(1,0.8,N), y, 0)\n",
    "a = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)\n",
    "def CondatP_1d(y,a,N):\n",
    "    x = zeros_like(y)\n",
    "    if a == 0:\n",
    "        return x\n",
    "    \n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "    v = [0]\n",
    "    u = []\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(n)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [n]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v.append(n)\n",
    "                ρ += (yₙ - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for i,j in enumerate(v):\n",
    "            if y[j] <= ρ:\n",
    "                ρ += (ρ - y[j])/(len(v) - 1)\n",
    "                del v[i]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "    \n",
    "    #x[v] = y[v] - ρ\n",
    "    for n in iter(v):\n",
    "        x[n] = y[n] - ρ\n",
    "    #for n in prange(len(v)):\n",
    "    #    x[v[n]] = y[v[n]] - ρ\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run things once for pre-compiling:\n",
    "CondatP_1d(y,a,N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we run the above again, we can see a clear speed-up. The computation passes quickly even inside compositions\n",
    "allclose(CondatP_1d(y,a,N).sum(), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we addapt the code to accept a matrix $\\gamma$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 500\n",
    "M = 1000\n",
    "γ = rng(0).uniform(-1,2,(M,N));    γ = where(rng(0).binomial(1,0.8,(M,N)), γ, 0)\n",
    "a = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can pre-allocate some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = zeros_like(γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "center",
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)\n",
    "def CondatP(y,x,a,N):\n",
    "    if a == 0:\n",
    "        return x\n",
    "    \n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "    v = [0]\n",
    "    u = []\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(n)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [n]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v.append(n)\n",
    "                ρ += (yₙ - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for i,j in enumerate(v):\n",
    "            if y[j] <= ρ:\n",
    "                ρ += (ρ - y[j])/(len(v) - 1)\n",
    "                del v[i]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "    \n",
    "    #x[v] = y[v] - ρ\n",
    "    for n in iter(v):\n",
    "        x[n] = y[n] - ρ\n",
    "    #for n in prange(len(v)):\n",
    "    #    x[v[n]] = y[v[n]] - ρ\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CondatP(γ[0],x[0],a,M); # Null test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.007713794708251953 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x = zeros_like(γ)\n",
    "for i in range(M):    x[i] = CondatP(γ[i],x[i],a,N)\n",
    "end = time.time()\n",
    "print('Time taken:',end-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allclose(x.sum(axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An additional test can be to see what happens if we work on the support of $\\gamma$:\n",
    "```Python\n",
    "x = zeros_like(γ)\n",
    "for i in range(N):\n",
    "    z = γ[i][γ[i] != 0]\n",
    "    x[i][γ[i] != 0] = CondatP_1d(z,a,z.size)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not seem to be a significant gain on working with the support. This might change if the support is extremely small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run the Primal Dual algorithm addapted for DOT. To test it, we will run it against some of the DOTMark files. We will aim to transport from one given image to another, which are normalised and flattened in ```C```-order. The matrix of costs is based on a uniform grid within $[0,1]^2$ with $M$ points for the source and $N$ points for the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Microscopy_Sized'\n",
    "path = 'Exact/' + folder + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 instances in this location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data8_1002-data8_1010_p=S2',\n",
       " 'data32_1002-data32_1010_p=S2',\n",
       " 'data16_1002-data16_1010_p=S2',\n",
       " 'data64_1002-data64_1010_p=S2']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = [f[:-9] for f in os.listdir(path) if f.endswith('.txt')]\n",
    "print('There are', len(files), 'instances in this location:')\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = files[1]\n",
    "full_path = path + instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.load(full_path + '_m.npy');    M = m.size\n",
    "n = np.load(full_path + '_n.npy');    N = n.size\n",
    "c = np.load(full_path + '_Cost.npy')\n",
    "sol = np.load(full_path + '_Sol.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(full_path + '_Time.txt', 'r') as f:\n",
    "    obj_exact = eval((f.readlines())[0])['Obj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "In what follows, we provide tests for the chosen instance running the Entropic Regularisation approach given by M. Cuturi in 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://github.com/rflamary/POT/blob/master/ot/bregman.py ###\n",
    "def sinkhorn_knopp(M,a,b, reg, numItermax=1000,\n",
    "                   stopThr=1e-9, verbose=False,collect_obj = False, \n",
    "                   true_obj = None, true_obj_tol = 1e-4,\n",
    "                   true_solution = None, save_iter = False, **kwargs):\n",
    "    r\"\"\"\n",
    "    Solve the entropic regularization optimal transport problem and return the OT matrix\n",
    "    The function solves the following optimization problem:\n",
    "    .. math::\n",
    "        \\gamma = arg\\min_\\gamma <\\gamma,M>_F + reg\\cdot\\Omega(\\gamma)\n",
    "        s.t. \\gamma 1 = a\n",
    "             \\gamma^T 1= b\n",
    "             \\gamma\\geq 0\n",
    "    where :\n",
    "    - M is the (dim_a, dim_b) metric cost matrix\n",
    "    - :math:`\\Omega` is the entropic regularization term :math:`\\Omega(\\gamma)=\\sum_{i,j} \\gamma_{i,j}\\log(\\gamma_{i,j})`\n",
    "    - a and b are source and target weights (histograms, both sum to 1)\n",
    "    The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in [2]_\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : ndarray, shape (dim_a,)\n",
    "        samples weights in the source domain\n",
    "    b : ndarray, shape (dim_b,) or ndarray, shape (dim_b, n_hists)\n",
    "        samples in the target domain, compute sinkhorn with multiple targets\n",
    "        and fixed M if b is a matrix (return OT loss + dual variables in log)\n",
    "    M : ndarray, shape (dim_a, dim_b)\n",
    "        loss matrix\n",
    "    reg : float\n",
    "        Regularization term >0\n",
    "    numItermax : int, optional\n",
    "        Max number of iterations\n",
    "    stopThr : float, optional\n",
    "        Stop threshol on error (>0)\n",
    "    verbose : bool, optional\n",
    "        Print information along iterations\n",
    "    log : bool, optional\n",
    "        record log if True\n",
    "    Returns\n",
    "    -------\n",
    "    gamma : ndarray, shape (dim_a, dim_b)\n",
    "        Optimal transportation matrix for the given parameters\n",
    "    log : dict\n",
    "        log dictionary return only if log==True in parameters\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import ot\n",
    "    >>> a=[.5, .5]\n",
    "    >>> b=[.5, .5]\n",
    "    >>> M=[[0., 1.], [1., 0.]]\n",
    "    >>> ot.sinkhorn(a, b, M, 1)\n",
    "    array([[0.36552929, 0.13447071],\n",
    "           [0.13447071, 0.36552929]])\n",
    "    References\n",
    "    ----------\n",
    "    .. [2] M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013\n",
    "    See Also\n",
    "    --------\n",
    "    ot.lp.emd : Unregularized OT\n",
    "    ot.optim.cg : General regularized OT\n",
    "    \"\"\"\n",
    "    #Initialisations\n",
    "    \n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    b = np.asarray(b, dtype=np.float64)\n",
    "    M = np.asarray(M, dtype=np.float64)\n",
    "\n",
    "    if len(a) == 0:\n",
    "        a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "    if len(b) == 0:\n",
    "        b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    if len(b.shape) > 1:\n",
    "        n_hists = b.shape[1]\n",
    "    else:\n",
    "        n_hists = 0\n",
    "        \n",
    "    if n_hists:\n",
    "        u = np.ones((dim_a, n_hists)) / dim_a\n",
    "        v = np.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u = np.ones(dim_a) / dim_a\n",
    "        v = np.ones(dim_b) / dim_b\n",
    "        \n",
    "    K = np.empty(M.shape, dtype=M.dtype)\n",
    "    np.divide(M, -reg, out=K)\n",
    "    np.exp(K, out=K)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    tmp2 = np.empty(b.shape, dtype=M.dtype)\n",
    "\n",
    "    Kp = (1 / (a+ 1e-299)).reshape(-1, 1) * K\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    \n",
    "    '''\n",
    "        Information from true solution (if available)\n",
    "    '''\n",
    "    # Store current objective value\n",
    "    if collect_obj == True:\n",
    "        x = u.reshape((-1, 1)) * K * v.reshape((1, -1))\n",
    "        obj = [np.multiply(M,u.reshape((-1, 1)) * K * v.reshape((1, -1))).sum()]\n",
    "    \n",
    "    \n",
    "    # Norm of true solution\n",
    "    if true_solution is not None:\n",
    "        true_obj_crit = 1.0\n",
    "        if true_obj is None:\n",
    "            true_obj = np.tensordot(M,sol,2).item()\n",
    "        print('Objective from ground truth:', obj_exact,'\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Iterate the Entropic Regularisation scheme\n",
    "    '''\n",
    "    \n",
    "    every_iter = {'it':[], 'obj':[], 'dist_obj':[], 'time':[], 'dist_x':[]}\n",
    "    every_critical = {'it':[], 'obj':[], 'tol':[], 'dist_obj':[], 'time':[], 'dist_x':[]}\n",
    "    \n",
    "    if true_solution is not None:\n",
    "        print('     It  |  Tolerance |        Time       | Frob. dist. ')\n",
    "        print( '{:-^55}'.format('') )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Initial Time\n",
    "    start = time.time()\n",
    "    \n",
    "    while (err > stopThr and cpt < numItermax):\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "\n",
    "        KtransposeU = np.dot(K.T, u)\n",
    "        v = np.divide(b, (KtransposeU+ 1e-299))\n",
    "        u = 1. / (np.dot(Kp, v)+ 1e-299)\n",
    "\n",
    "        if (np.any(KtransposeU == 0)\n",
    "                or np.any(np.isnan(u)) or np.any(np.isnan(v))\n",
    "                or np.any(np.isinf(u)) or np.any(np.isinf(v))):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "        if cpt % 10 == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                np.einsum('ik,ij,jk->jk', u, K, v, out=tmp2)\n",
    "            else:\n",
    "                # compute right marginal tmp2= (diag(u)Kdiag(v))^T1\n",
    "                np.einsum('i,ij,j->j', u, K, v, out=tmp2)\n",
    "            err = np.linalg.norm(tmp2 - b)  # violation of marginal\n",
    "            if verbose:\n",
    "                if cpt % 200 == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "        \n",
    "        # Measure time up to this point!\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update objective function\n",
    "        if collect_obj == True:\n",
    "            obj.append(np.multiply(M,u.reshape((-1, 1)) * K * v.reshape((1, -1))).sum())\n",
    "            # Compute relative objective distance\n",
    "            if true_solution is not None:\n",
    "                dist_true_sol = abs(obj[-1] - true_obj)/true_obj\n",
    "        \n",
    "        # If all iterations are to be stored:\n",
    "        if save_iter == True:\n",
    "            x = u.reshape((-1, 1)) * K * v.reshape((1, -1))\n",
    "            frob_d = norm(sol-x, 'fro')/norm(sol, 'fro')\n",
    "            \n",
    "            every_iter['it'].append(cpt)\n",
    "            every_iter['obj'].append(obj[-1])\n",
    "            every_iter['dist_obj'].append( dist_true_sol if true_obj is not None else np.nan )\n",
    "            every_iter['time'].append( end-start )\n",
    "            every_iter['dist_x'].append( frob_d )\n",
    "        \n",
    "        # If a true solution is available, we check the tolerance:\n",
    "        if true_solution is not None: \n",
    "            if dist_true_sol < true_obj_crit:\n",
    "                \n",
    "                x = u.reshape((-1, 1)) * K * v.reshape((1, -1))\n",
    "                frob_d = norm(sol-x, 'fro')/norm(sol, 'fro')\n",
    "                \n",
    "                every_critical['it'].append( cpt )\n",
    "                every_critical['obj'].append( obj[-1] )\n",
    "                every_critical['tol'].append( true_obj_crit )\n",
    "                every_critical['dist_obj'].append( dist_true_sol )\n",
    "                every_critical['time'].append( end-start )\n",
    "                every_critical['dist_x'].append( frob_d )\n",
    "                \n",
    "                print('* {0:6.0f} |    {1:.1e} | {2:15.2f} s |    {3:4.4f}'.format(cpt,true_obj_crit,end-start,frob_d))\n",
    "                \n",
    "                # If the prescribed tolerance is reached, we finish.\n",
    "                if dist_true_sol < true_obj_tol:\n",
    "                    print('Solution found with given tolerance.')\n",
    "                    break\n",
    "                \n",
    "                # Adjust current level of inner tolerance\n",
    "                true_obj_crit *= 0.1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        cpt = cpt + 1 #number of iterations\n",
    "\n",
    "    if true_solution is not None:\n",
    "        print( '{:-^55}'.format('') )\n",
    "    \n",
    "    print('\\nAlgorithm stopped after {0:.4f} seconds and {1} iterations'.format(end-start,cpt))\n",
    "    \n",
    "    x = u.reshape((-1, 1)) * K * v.reshape((1, -1))\n",
    "    obj = np.multiply(M,u.reshape((-1, 1)) * K * v.reshape((1, -1))).sum()\n",
    "    \n",
    "    if collect_obj == False and save_iter == True:\n",
    "        return x, every_iter\n",
    "    if collect_obj == True and save_iter == True:\n",
    "        return x, obj, every_critical, every_iter\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective from ground truth: 0.010675024052995653 \n",
      "\n",
      "     It  |  Tolerance |        Time       | Frob. dist. \n",
      "-------------------------------------------------------\n",
      "*      0 |    1.0e+00 |            0.01 s |    1.6422\n"
     ]
    }
   ],
   "source": [
    "x, obj, every_critical, every_iter = sinkhorn_knopp(c,m,n,0.0002, numItermax= 10000, collect_obj = True, true_obj = obj_exact,true_obj_tol = 1e-7,true_solution = sol, save_iter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise and store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = folder + '_Results'\n",
    "out_folder  = main_folder + '/' + instance\n",
    "algorithm   = 'ER-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if main folder for results exists, else create it\n",
    "if not os.path.exists(main_folder):    os.makedirs(main_folder)\n",
    "# Now create a folder for the results of the instance\n",
    "if not os.path.exists(out_folder):    os.makedirs(out_folder)\n",
    "out_folder += '/' + algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualise solution\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.spy(x, markersize=1, aspect = 1, markeredgecolor = 'black', alpha=0.75);    plt.axis('off')\n",
    "plt.title('Sparse view')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x);    plt.axis('off');    plt.title('Heat map\\n')\n",
    "\n",
    "plt.savefig(out_folder+'Sparse-Heat.pdf', bbox_inches='tight',transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualise evolution of objective values\n",
    "plt.figure(figsize = (20,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(obj)\n",
    "plt.axhline(y=obj_exact, color='r', linestyle=':')\n",
    "plt.xlabel('Iteration count');    plt.ylabel('Objective cost');    plt.title('Objective values per iteration')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(obj)\n",
    "plt.axhline(y=obj_exact, color='r', linestyle=':')\n",
    "plt.yscale('log')\n",
    "plt.title('Objective values per iteration')\n",
    "plt.xlabel('Iteration count');    plt.ylabel('Objective cost (log scale)')\n",
    "\n",
    "plt.savefig(out_folder+'Objective.pdf', bbox_inches='tight',transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualise evolution of relative errors\n",
    "plt.figure(figsize = (20,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(every_iter['dist_obj'])\n",
    "plt.yscale('log')\n",
    "plt.title('Error in objective per iteration')\n",
    "plt.xlabel('Iteration count');    plt.ylabel('Relative error in objective (log scale)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(every_iter['dist_x'])\n",
    "plt.yscale('log')\n",
    "plt.title('Error in solution per iteration')\n",
    "plt.xlabel('Iteration count');    plt.ylabel('Relative error in solution (log scale)')\n",
    "\n",
    "plt.savefig(out_folder+'Rel_Error.pdf', bbox_inches='tight',transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data from the above two plots is also available as dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critical = pd.DataFrame.from_dict(every_critical)\n",
    "df_critical.to_pickle(out_folder+'Critical.pkl') # To read back use pd.read_pickle(file_name)\n",
    "df_critical.to_excel(out_folder+'Critical.xlsx')\n",
    "display(df_critical)\n",
    "\n",
    "# If we want this table in LaTeX format run:\n",
    "print(df_critical.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every = pd.DataFrame.from_dict(every_iter)\n",
    "df_every.to_pickle(out_folder+'Every.pkl') # To read back use pd.read_pickle(file_name)\n",
    "df_every.to_excel(out_folder+'Every.xlsx')\n",
    "display(df_every.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, store the latest solution:\n",
    "np.save(out_folder + '_Sol.npy' , x)            # To read back just run:   np.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Code used to do performance tests in each piece of code:\n",
    "```Python\n",
    "start = time.time()\n",
    "# ...\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "%timeit -r 10 -n 200 `function(x)`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
