{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal Dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection onto the simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "This notebook implements an algorithm for the projection of a vector $y$ onto the simplex $\\Delta$ with\n",
    "\\begin{align}\n",
    "    \\Delta := \\Big\\{ (x_1,\\ldots,x_N)\\in \\mathbb{R}^N:\\, \\sum_{n=1}^N x_n =a \\quad\\text{and}\\quad x\\geq 0 \\Big\\}.\n",
    "\\end{align}\n",
    "    \n",
    "The implemented algorithm was proposed in: Condat, L. <i>Fast projection onto the simplex and the ℓ<sub>1</sub> ball</i>. Math. Program. 158, 575–585 (2016). [https://doi.org/10.1007/s10107-015-0946-6](https://doi.org/10.1007/s10107-015-0946-6). \n",
    "    \n",
    "The paper is also available at [https://hal.archives-ouvertes.fr/hal-01056171v2](https://hal.archives-ouvertes.fr/hal-01056171v2).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); vertical-align: middle; padding:5px 0; padding-left: 40px;\">\n",
    "<h2 style=\"color: #5e9ca0;\">Condat's Algorithm</h2>\n",
    "<ol>\n",
    "<li>Set $v:= (y_1)$, $u$ as an empty list, $\\rho:= y_1 - a$.</li>\n",
    "<li>For $n \\in \\{2,\\ldots, N\\}$, do\n",
    "<ol>\n",
    "<li>If $y_n > \\rho$\n",
    "<ol>\n",
    "<li>Set $\\rho := \\rho + (y_n - \\rho)/(|v|+1)$.</li>\n",
    "<li>If $\\rho > y_n - a$, add $y_n$ to $v$.</li>\n",
    "<li>Else, add $v$ to $u$, set $v = (y_n)$, $\\rho = y_n -a$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>If $u$ is not empty, for every element $y$ of $u$, do\n",
    "<ol>\n",
    "<li>If $y > \\rho$, add $y$ to $v$ and set $\\rho := \\rho + (y-\\rho)/|v|$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>Do, while $|v|$ changes,\n",
    "<ol>\n",
    "<li>For every element $y$ of $v$ do\n",
    "<ol>\n",
    "<li>If $y\\leq \\rho$, remove $y$ from $v$ and set $\\rho := \\rho + (\\rho - y)/|v|$.</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "<li>Set $\\tau := \\rho$, $K = |v|$.</li>\n",
    "<li>For $n \\in \\{1,\\ldots,N\\}$, set $x_n := \\max \\{y_n - \\tau, 0\\}$.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm will be tested projecting a random vector $y$ of size $N$ where $y_n \\sim \\mathcal{U}(-1,2)$ for all $n\\in \\{1,\\ldots,N\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nditer, ndenumerate, zeros, zeros_like, clip, allclose, full, maximum\n",
    "from numpy.random import default_rng as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "y = rng(0).uniform(-1,2,N)\n",
    "a = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "First implementation is list-based. It sticks to the algorithm above, and thus it cannot take the advantage that $v$ is the list of positive values of $y$, thus requiring the unnecessary triming in Step 6.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "v = [y[0]]\n",
    "u = []\n",
    "ρ = y[0] - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "for n in range(1,N):\n",
    "    yₙ = y[n]\n",
    "    if yₙ > ρ:\n",
    "        ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "        if ρ > yₙ - a:\n",
    "            v.append(yₙ)\n",
    "        else:\n",
    "            u.extend(v)\n",
    "            v = [yₙ]\n",
    "            ρ = yₙ - a\n",
    "# Step 3\n",
    "if len(u) > 0:\n",
    "    for ι in iter(u):\n",
    "        if ι > ρ:\n",
    "            v.append(ι)\n",
    "            ρ += (ι - ρ)/( len(v) )\n",
    "# Step 4\n",
    "while True:\n",
    "    ℓ_v = len(v)\n",
    "    for ı in range(ℓ_v - 1, -1, -1):\n",
    "        if v[ı] <= ρ:\n",
    "            ρ += (ρ - v[ı])/(len(v) - 1)\n",
    "            del v[ı]\n",
    "    if len(v) >= ℓ_v:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clip(y - ρ, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06744738, 0.01832359, 0.06110709, 0.01940269, 0.00520454,\n",
       "       0.06056962, 0.02164565, 0.01061472, 0.04190357, 0.05789789,\n",
       "       0.02130254, 0.0148837 , 0.06684845, 0.05188726, 0.00241651,\n",
       "       0.04805173, 0.0173415 , 0.02582169, 0.03312648, 0.07432163,\n",
       "       0.02410941, 0.01056192, 0.03883018, 0.03691761, 0.05087173,\n",
       "       0.00455268, 0.06171698, 0.05232123])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v - ρ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorial version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The following adaptation introduces some array operations to avoid the extra step of clipping negative numbers. Here $v$ is not a set but a boolean array of the same size as $y$. Its cells determine if a cell of $y$ is active in $v$ or not. In the end, $x$ is computed just on the active cells given by $v$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "ρ = y[0] - a\n",
    "\n",
    "v = zeros(N, dtype=bool)\n",
    "x = zeros_like(y)\n",
    "u = []\n",
    "v[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "for n in range(1,N):\n",
    "    yₙ = y[n]\n",
    "    if yₙ > ρ:\n",
    "        ρ += (yₙ - ρ)/( v.sum() + 1 )\n",
    "        if ρ > yₙ - a:\n",
    "            v[n] = True\n",
    "        else:\n",
    "            u.extend([i[0] for i,j in ndenumerate(v) if j])\n",
    "            v *= False;    v[n] = True\n",
    "            ρ = yₙ - a\n",
    "# Step 3\n",
    "if len(u) > 0:\n",
    "    for n in iter(u):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            v[n] = True\n",
    "            ρ += (yₙ - ρ)/( v.sum() )\n",
    "# Step 4\n",
    "while True:\n",
    "    ℓ_v = v.sum()\n",
    "    for i,j in ndenumerate(v):\n",
    "        if j:\n",
    "            if y[i[0]] <= ρ:\n",
    "                ρ += (ρ - y[i[0]])/(v.sum() - 1)\n",
    "                v[i[0]] = False\n",
    "    if v.sum() >= ℓ_v:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[v] = y[v] - ρ #clip(y[v] - ρ, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06744738, 0.01832359, 0.06110709, 0.01940269, 0.00520454,\n",
       "       0.06056962, 0.02164565, 0.01061472, 0.04190357, 0.05789789,\n",
       "       0.02130254, 0.0148837 , 0.06684845, 0.05188726, 0.00241651,\n",
       "       0.04805173, 0.0173415 , 0.02582169, 0.03312648, 0.07432163,\n",
       "       0.02410941, 0.01056192, 0.03883018, 0.03691761, 0.05087173,\n",
       "       0.00455268, 0.06171698, 0.05232123])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorial version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The final implementation takes back the original idea of using lists instead of an array of the same size as $y$. In this case, $v$ does not contain values from $y$ but its indeces. This way a sparse representation of $v$ is achieved and $x$ does not go through a clipping step as well.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "ρ = y[0] - a\n",
    "\n",
    "x = zeros_like(y)\n",
    "v = [0]\n",
    "u = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "center",
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "for n in range(1,N):\n",
    "    yₙ = y[n]\n",
    "    if yₙ > ρ:\n",
    "        ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "        if ρ > yₙ - a:\n",
    "            v.append(n)\n",
    "        else:\n",
    "            u.extend(v)\n",
    "            v = [n]\n",
    "            ρ = yₙ - a\n",
    "# Step 3\n",
    "if len(u) > 0:\n",
    "    for n in iter(u):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            v.append(n)\n",
    "            ρ += (yₙ - ρ)/( len(v) )\n",
    "# Step 4\n",
    "while True:\n",
    "    ℓ_v = len(v)\n",
    "    for i,j in enumerate(v):\n",
    "        if y[j] <= ρ:\n",
    "            ρ += (ρ - y[j])/(len(v) - 1)\n",
    "            del v[i]\n",
    "    if len(v) >= ℓ_v:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[v] = y[v] - ρ #clip(y[v] - ρ, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06744738, 0.01832359, 0.06110709, 0.01940269, 0.00520454,\n",
       "       0.06056962, 0.02164565, 0.01061472, 0.04190357, 0.05789789,\n",
       "       0.02130254, 0.0148837 , 0.06684845, 0.05188726, 0.00241651,\n",
       "       0.04805173, 0.0173415 , 0.02582169, 0.03312648, 0.07432163,\n",
       "       0.02410941, 0.01056192, 0.03883018, 0.03691761, 0.05087173,\n",
       "       0.00455268, 0.06171698, 0.05232123])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now we check which routine is the fastest.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     6,
     17,
     23,
     34,
     43,
     54,
     61,
     74,
     82,
     93,
     100
    ]
   },
   "outputs": [],
   "source": [
    "def CondatP_a(y,a,N):\n",
    "    # Step 1\n",
    "    v = [y[0]]\n",
    "    u = []\n",
    "    ρ = y[0] - a\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(yₙ)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [yₙ]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for ι in iter(u):\n",
    "            if ι > ρ:\n",
    "                v.append(ι)\n",
    "                ρ += (ι - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for ı in range(ℓ_v - 1, -1, -1):\n",
    "            if v[ı] <= ρ:\n",
    "                ρ += (ρ - v[ı])/(len(v) - 1)\n",
    "                del v[ı]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "            \n",
    "    return clip(y - ρ, 0, None)\n",
    "\n",
    "def CondatP_b(y,a,N):\n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "\n",
    "    v = zeros(N, dtype=bool)\n",
    "    x = zeros_like(y)\n",
    "    u = []\n",
    "    v[0] = True\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( v.sum() + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v[n] = True\n",
    "            else:\n",
    "                u.extend([i[0] for i,j in ndenumerate(v) if j])\n",
    "                v *= False;    v[n] = True\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v[n] = True\n",
    "                ρ += (yₙ - ρ)/( v.sum() )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = v.sum()\n",
    "        for i,j in ndenumerate(v):\n",
    "            if j:\n",
    "                if y[i[0]] <= ρ:\n",
    "                    ρ += (ρ - y[i[0]])/(v.sum() - 1)\n",
    "                    v[i[0]] = False\n",
    "        if v.sum() >= ℓ_v:\n",
    "            break\n",
    "\n",
    "    x[v] = y[v] - ρ \n",
    "    return x\n",
    "\n",
    "def CondatP_c(y,a,N):\n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "\n",
    "    x = zeros_like(y)\n",
    "    v = [0]\n",
    "    u = []\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(n)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [n]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v.append(n)\n",
    "                ρ += (yₙ - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for i,j in enumerate(v):\n",
    "            if y[j] <= ρ:\n",
    "                ρ += (ρ - y[j])/(len(v) - 1)\n",
    "                del v[i]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "    \n",
    "    x[v] = y[v] - ρ\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 µs ± 59.3 µs per loop (mean ± std. dev. of 10 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 200 CondatP_a(y,a,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.57 ms ± 83.8 µs per loop (mean ± std. dev. of 10 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 200 CondatP_b(y,a,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 µs ± 36.8 µs per loop (mean ± std. dev. of 10 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 200 CondatP_c(y,a,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the last implementation might be a little faster than the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just-in-time compilation with numba\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "We use numba to speed up the computation time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True, parallel = True)\n",
    "def CondatP_a(y,a,N):\n",
    "    # Step 1\n",
    "    v = [y[0]]\n",
    "    u = []\n",
    "    ρ = y[0] - a\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(yₙ)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [yₙ]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for ι in iter(u):\n",
    "            if ι > ρ:\n",
    "                v.append(ι)\n",
    "                ρ += (ι - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for ı in range(ℓ_v - 1, -1, -1):\n",
    "            if v[ı] <= ρ:\n",
    "                ρ += (ρ - v[ı])/(len(v) - 1)\n",
    "                del v[ı]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "            \n",
    "    return maximum(y - ρ, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True, parallel = True)\n",
    "def CondatP_b(y,a,N):\n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "\n",
    "    v = full(N, False)\n",
    "    x = zeros_like(y)\n",
    "    u = []\n",
    "    v[0] = True\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( v.sum() + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v[n] = True\n",
    "            else:\n",
    "                u.extend([i[0] for i,j in ndenumerate(v) if j])\n",
    "                v *= False;    v[n] = True\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v[n] = True\n",
    "                ρ += (yₙ - ρ)/( v.sum() )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = v.sum()\n",
    "        for i,j in ndenumerate(v):\n",
    "            if j:\n",
    "                if y[i[0]] <= ρ:\n",
    "                    ρ += (ρ - y[i[0]])/(v.sum() - 1)\n",
    "                    v[i[0]] = False\n",
    "        if v.sum() >= ℓ_v:\n",
    "            break\n",
    "\n",
    "    x[v] = y[v] - ρ \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)#, parallel = True)\n",
    "def CondatP_c(y,a,N):\n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "\n",
    "    x = zeros_like(y)\n",
    "    v = [0]\n",
    "    u = []\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(n)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [n]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v.append(n)\n",
    "                ρ += (yₙ - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for i,j in enumerate(v):\n",
    "            if y[j] <= ρ:\n",
    "                ρ += (ρ - y[j])/(len(v) - 1)\n",
    "                del v[i]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "    \n",
    "    #x[v] = y[v] - ρ\n",
    "    for n in iter(v):\n",
    "        x[n] = y[n] - ρ\n",
    "    #for n in prange(len(v)):\n",
    "    #    x[v[n]] = y[v[n]] - ρ\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run things once for pre-compiling:\n",
    "CondatP_a(y,a,N), CondatP_b(y,a,N), CondatP_c(y,a,N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see a clear winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.31 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "114 µs ± 61.4 µs per loop (mean ± std. dev. of 10 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 200 CondatP_a(y,a,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fb1a0904ce10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r 10 -n 200 CondatP_b(y,a,N)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 200 CondatP_b(y,a,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit -r 10 -n 200 CondatP_c(y,a,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allclose(CondatP_a(y,a,N), CondatP_b(y,a,N)), allclose(CondatP_a(y,a,N), CondatP_c(y,a,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally addapt the code to accept a matrix $\\gamma$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "M = 500\n",
    "γ = rng(0).uniform(-1,2,(N,M))\n",
    "a = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rng(0).uniform(-1,2,N)\n",
    "x = zeros_like(γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)#, parallel = True)\n",
    "def CondatP_c(y,x,a,N):\n",
    "    # Step 1\n",
    "    ρ = y[0] - a\n",
    "    v = [0]\n",
    "    u = []\n",
    "    # Step 2\n",
    "    for n in range(1,N):\n",
    "        yₙ = y[n]\n",
    "        if yₙ > ρ:\n",
    "            ρ += (yₙ - ρ)/( len(v) + 1 )\n",
    "            if ρ > yₙ - a:\n",
    "                v.append(n)\n",
    "            else:\n",
    "                u.extend(v)\n",
    "                v = [n]\n",
    "                ρ = yₙ - a\n",
    "    # Step 3\n",
    "    if len(u) > 0:\n",
    "        for n in iter(u):\n",
    "            yₙ = y[n]\n",
    "            if yₙ > ρ:\n",
    "                v.append(n)\n",
    "                ρ += (yₙ - ρ)/( len(v) )\n",
    "    # Step 4\n",
    "    while True:\n",
    "        ℓ_v = len(v)\n",
    "        for i,j in enumerate(v):\n",
    "            if y[j] <= ρ:\n",
    "                ρ += (ρ - y[j])/(len(v) - 1)\n",
    "                del v[i]\n",
    "        if len(v) >= ℓ_v:\n",
    "            break\n",
    "    \n",
    "    #x[v] = y[v] - ρ\n",
    "    for n in iter(v):\n",
    "        x[n] = y[n] - ρ\n",
    "    #for n in prange(len(v)):\n",
    "    #    x[v[n]] = y[v[n]] - ρ\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CondatP_c(y,x,a,N); # Null test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    x[i] = CondatP_c(γ[i],x[i],a,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "27\n",
      "77\n",
      "94\n",
      "163\n",
      "171\n",
      "194\n",
      "198\n",
      "239\n",
      "252\n",
      "275\n",
      "278\n",
      "308\n",
      "349\n",
      "368\n",
      "405\n",
      "412\n",
      "414\n",
      "497\n",
      "530\n",
      "698\n",
      "734\n",
      "736\n",
      "745\n",
      "762\n",
      "790\n",
      "799\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "# Just checking :)\n",
    "for i in range(N):\n",
    "    if x[i].sum() > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        , 33.17240125,  9.86861806,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        , 30.57583176,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        , 10.29389086,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  3.51899761,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        , 29.83113873,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        , 11.38991396,\n",
       "        1.        ,  1.        ,  1.        ,  6.09506379,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        , 20.98800518,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        , 28.84888429,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "       11.24652333,  1.        ,  1.        ,  8.11440871,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        , 33.22095479,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        , 25.80211049,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  2.16475781,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "       24.16093358,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  9.34126161,  1.        , 13.47187838,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        , 16.93383702,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "       36.82302637,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        , 12.64484517,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  6.08028196,\n",
       "        1.        , 19.67731835,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "       18.57278016,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        , 25.3166868 ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        3.16707561,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        , 30.56243575,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        , 26.27115617,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)#, parallel = True)\n",
    "def primal_dual(c,m,n,iters):\n",
    "    #Algorithm for calculating solution x, in the primal space\n",
    "    #and y_1, y_2 in the dual space.\n",
    "    #Also returns the value of the objective function c*x at each\n",
    "    #iteration.\n",
    "    \n",
    "    #Initialise tau\n",
    "    tau = 0.0001\n",
    "    \n",
    "    #Initialise sigma\n",
    "    sig = 1/(tau*2) - 0.5\n",
    "    \n",
    "    #fetch lengths of m and n.\n",
    "    N = n.size\n",
    "    M = m.size\n",
    "    \n",
    "    #Initialise x\n",
    "    x = np.zeros((M,N))\n",
    "    x[:,0] = m\n",
    "    x[0,:] = n\n",
    "    x[0,0] = 0.5*(m[-1] + n[-1])\n",
    "    \n",
    "    #Initialise y_1 and y_2\n",
    "    y_1 = zeros((M,N))\n",
    "    y_2 = zeros((M,N))\n",
    "    \n",
    "    y_1[0,:] = n\n",
    "    y_2[:,0] = m\n",
    "    \n",
    "    #Save that objective function\n",
    "    obj = [np.sum(np.multiply(c,x))]\n",
    "    \n",
    "    \n",
    "    for k in range(iters):\n",
    "        #update x\n",
    "        xnew = x - tau*c - tau*(y_1 + y_2)\n",
    "        \n",
    "        #matrices for projection over the simplex C_1^m and the simplex C_2^n.\n",
    "        γ_1 = (1/sig)*y_1 + 2*xnew - x\n",
    "        γ_2 = (1/sig)*y_2 + 2*xnew - x\n",
    "        \n",
    "        \n",
    "        x_1 = zeros_like(γ_1)\n",
    "        for i in range(M):\n",
    "            x_1[i] = CondatP_c(γ_1[i],x_1[i],m[i],N)\n",
    "        \n",
    "        x_2 = zeros_like(γ_2)\n",
    "        for i in range(N):\n",
    "            x_2[:,i] = CondatP_c(γ_2[:,i],x_2[:,i],n[i],M)\n",
    "            \n",
    "        \n",
    "        #update x using the projection over the simplex C_1^m\n",
    "        y_1new = y_1 + sig*(2*xnew - x) - sig*x_1\n",
    "  \n",
    "        #update x using the projection over the simplex C_2^n\n",
    "        y_2new = y_2 + sig*(2*xnew - x) - sig*x_2\n",
    "        \n",
    "        #Reset x,y_1, y_2 for the next iteration\n",
    "        x = xnew\n",
    "        y_1 = y_1new\n",
    "        y_2 = y_2new\n",
    "        \n",
    "        #update objective function\n",
    "        obj.append(np.sum(np.multiply(c,x)))\n",
    "        \n",
    "    return x,obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Primal Dual = 199.05631470680237\n",
      "0.9990457115760565\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "x = np.linspace(0,1,1000)\n",
    "y = np.linspace(1,2,1000)\n",
    "len_x = np.size(x)\n",
    "len_y = np.size(y)\n",
    "\n",
    "c = np.zeros((len_x,len_y))\n",
    "for i in range(len_x):\n",
    "    for j in range(len_y):\n",
    "        c[i,j] = (y[j]-x[i])**2\n",
    "\n",
    "m = np.ones(len_x)/len_x\n",
    "n = np.ones(len_y)/len_y\n",
    "M = len_x\n",
    "N = len_y\n",
    "\n",
    "t = time.time()\n",
    "[x,obj] = primal_dual(c,m,n,500)\n",
    "elapsed = time.time() - t\n",
    "print('Time taken for Primal Dual =', elapsed)\n",
    "print(obj[-1])\n",
    "#plt.plot(obj)\n",
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#set parameters accordingly.\n",
    "M = 4                  \n",
    "N = 4\n",
    "m = 0.25*np.ones(M)\n",
    "n = 0.25*np.ones(N)\n",
    "c = np.array([[3.10112791, 2.01924761, 2.        , 2.01924761],\n",
    "     [3.10112791, 3.        , 1.16637984, 1.        ],\n",
    "     [3.        , 3.10112791, 1.16637984, 2.01924761],\n",
    "     [1.        , 3.        , 2.33275967, 4.22075809]])\n",
    "[x,obj] = primal_dual(c,m,n,100)\n",
    "plt.plot(obj)\n",
    "print(obj[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalised Forward-Backward Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "This implements a generalised forward-backward split approach for the OT problem.\n",
    "    \n",
    "The implemented algorithm was proposed in: Raguet. H, Fadili. J, Peyre. G <i>Generalised Forward-Backward Splitting</i>. SIAM Journal on Imaging Sciences. (2013)\n",
    "    \n",
    "A preprint of the paper is available at https://arxiv.org/pdf/1108.4404.pdf\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath = True)#, parallel = True)\n",
    "def generalised_forward_backward(c,m,n,iters):\n",
    "    #Algorithm for calculating solution x, in the primal space\n",
    "    #and y_1, y_2 in the dual space.\n",
    "    #Also returns the value of the objective function c*x at each\n",
    "    #iteration.\n",
    "    \n",
    "    #First compute ?\n",
    "    mu = np.linalg.norm(c,2)     # 1 -> 10^-1 -> 10^-2 -> ...\n",
    "    # ? is selected as the midpoint of the interval\n",
    "    #e = 1/mu #0.5 * 1/mu;        # remove\n",
    "    # ? does not depend on the current iteration\n",
    "    gam = 0.0001\n",
    "    #likewise, we do not require a change in ?\n",
    "    lam = 1.0;   #1.0\n",
    "    \n",
    "    #fetch lengths of m and n.\n",
    "    N = n.size\n",
    "    M = m.size\n",
    "    \n",
    "    #Initialise x\n",
    "    #x = np.zeros((M,N))\n",
    "    #x[:,0] = m\n",
    "    #x[0,:] = n\n",
    "    #x[0,0] = 0.5*(m[-1] + n[-1])\n",
    "    \n",
    "    #Initialise y_1 and y_2\n",
    "    v_1 = zeros((M,N))\n",
    "    v_2 = zeros((M,N))\n",
    "    \n",
    "    v_1[0,:] = n\n",
    "    v_2[:,0] = m\n",
    "    \n",
    "    #Initialise x\n",
    "    x = 0.5*(v_1 + v_2)\n",
    "    \n",
    "    #Save that objective function\n",
    "    obj = [np.sum(np.multiply(c,x))]\n",
    "    \n",
    "   \n",
    "    \n",
    "    for k in range(iters):\n",
    "    \n",
    "        #matrices for projection over the simplex C_1^m and the simplex C_2^n.\n",
    "        γ_1 = 2*x - v_1 - gam*c\n",
    "        γ_2 = 2*x - v_2 - gam*c\n",
    "        \n",
    "        \n",
    "        x_1 = zeros_like(γ_1)\n",
    "        for i in range(M):\n",
    "            x_1[i] = CondatP_c(γ_1[i],x_1[i],m[i],N)\n",
    "        \n",
    "        x_2 = zeros_like(γ_2)\n",
    "        for i in range(N):\n",
    "            x_2[:,i] = CondatP_c(γ_2[:,i],x_2[:,i],n[i],M)\n",
    "            \n",
    "        \n",
    "        #update x using the projection over the simplex C_1^m\n",
    "        v_1new = v_1 + lam*(x_1 - x)\n",
    "  \n",
    "        #update x using the projection over the simplex C_2^n\n",
    "        v_2new = v_2  + lam*(x_2 - x)\n",
    "        \n",
    "        #Update x,v_1, v_2 for the next iteration\n",
    "        v_1 = v_1new\n",
    "        v_2 = v_2new\n",
    "        x = 0.5*(v_1 + v_2)\n",
    "        \n",
    "        #update objective function\n",
    "        obj.append(np.sum(np.multiply(c,x)))\n",
    "        \n",
    "        \n",
    "    return x,obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Forward Backward = 196.80392360687256\n",
      "0.9987908748831436\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0,1,1000)\n",
    "y = np.linspace(1,2,1000)\n",
    "len_x = np.size(x)\n",
    "len_y = np.size(y)\n",
    "\n",
    "c = np.zeros((len_x,len_y))\n",
    "for i in range(len_x):\n",
    "    for j in range(len_y):\n",
    "        c[i,j] = (y[j]-x[i])**2\n",
    "\n",
    "m = np.ones(len_x)/len_x\n",
    "n = np.ones(len_y)/len_y\n",
    "N = len_y\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "[x,obj] = generalised_forward_backward(c,m,n,500)\n",
    "elapsed = time.time() - t\n",
    "print('Time taken for Forward Backward =', elapsed)\n",
    "\n",
    "print(obj[-1])\n",
    "#plt.plot(obj)\n",
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "M = 4                  \n",
    "N = 4\n",
    "m = 0.25*np.ones(M)\n",
    "n = 0.25*np.ones(N)\n",
    "c = np.array([[3.10112791, 2.01924761, 2.        , 2.01924761],\n",
    "     [3.10112791, 3.        , 1.16637984, 1.        ],\n",
    "     [3.        , 3.10112791, 1.16637984, 2.01924761],\n",
    "     [1.        , 3.        , 2.33275967, 4.22075809]])\n",
    "[x,obj] = generalised_forward_backward(c,m,n,10000)\n",
    "plt.plot(obj)\n",
    "print(obj[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropic Regularisation for an Initial Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropic_regularisation(m,n,c,iters_max,eps= 0.025):\n",
    "    \n",
    "    #fetch lengths of m and n.\n",
    "    N = np.size(n)\n",
    "    M = np.size(m)\n",
    "    \n",
    "    #Gibbs Kernel\n",
    "    Geps = np.exp(-c/eps)\n",
    "    \n",
    "    cons = 1/np.sum(Geps)\n",
    "    a = np.ones(M)*cons\n",
    "    b = np.ones(N)*cons\n",
    "    norm_difference = 100\n",
    "    obj = []\n",
    "    Kp = (1/(n + 1e-299)).reshape(-1,1) * Geps\n",
    "    for i in range(iters_max):\n",
    "        #anew = np.multiply(m,np.reciprocal(np.matmul(Geps, b)))\n",
    "        #bnew = np.multiply(n,np.reciprocal(np.matmul(a.T, Geps).T))\n",
    "        #anew = np.divide(m,np.matmul(Geps, b))\n",
    "        #bnew = np.divide(n,np.matmul(a.T, Geps).T)\n",
    "        bnew = np.divide(m, np.dot(Geps.T, a)+1e-299)\n",
    "        anew = 1. / (np.dot(Kp,bnew)+1e-299)\n",
    "                \n",
    "        #anew = np.divide(m, Geps * b)\n",
    "        #bnew = np.divide(n, (a.T * Geps).T)\n",
    "        \n",
    "        \n",
    "        #x = a * Geps * b.T\n",
    "        #u = anew * Geps * bnew.T\n",
    "        x = np.multiply(a, np.multiply(Geps, b.T))\n",
    "        u = np.multiply(anew, np.multiply(Geps, bnew.T))\n",
    "        #x = a @ Geps @ b.T\n",
    "        #u = anew @ Geps @ bnew.T\n",
    "        \n",
    "        norm_difference = np.linalg.norm(x-u)\n",
    "        \n",
    "        a = anew\n",
    "        b = bnew\n",
    "        \n",
    "        obj.append((np.multiply(c,u)).sum())\n",
    "    \n",
    "    \n",
    "    return x, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4                  \n",
    "N = 4\n",
    "m = 0.25*np.ones(M)\n",
    "n = 0.25*np.ones(N)\n",
    "c = np.array([[3.10112791, 2.01924761, 2.        , 2.01924761],\n",
    "     [3.10112791, 3.        , 1.16637984, 1.        ],\n",
    "     [3.        , 3.10112791, 1.16637984, 2.01924761],\n",
    "     [1.        , 3.        , 2.33275967, 4.22075809]])\n",
    "x, obj = entropic_regularisation(m,n,c,100000)\n",
    "plt.plot(obj)\n",
    "print(obj[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://github.com/rflamary/POT/blob/master/ot/bregman.py ###\n",
    "def sinkhorn_knopp(a, b, M, reg, numItermax=1000,\n",
    "                   stopThr=1e-9, verbose=False, log=False, **kwargs):\n",
    "    r\"\"\"\n",
    "    Solve the entropic regularization optimal transport problem and return the OT matrix\n",
    "    The function solves the following optimization problem:\n",
    "    .. math::\n",
    "        \\gamma = arg\\min_\\gamma <\\gamma,M>_F + reg\\cdot\\Omega(\\gamma)\n",
    "        s.t. \\gamma 1 = a\n",
    "             \\gamma^T 1= b\n",
    "             \\gamma\\geq 0\n",
    "    where :\n",
    "    - M is the (dim_a, dim_b) metric cost matrix\n",
    "    - :math:`\\Omega` is the entropic regularization term :math:`\\Omega(\\gamma)=\\sum_{i,j} \\gamma_{i,j}\\log(\\gamma_{i,j})`\n",
    "    - a and b are source and target weights (histograms, both sum to 1)\n",
    "    The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in [2]_\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : ndarray, shape (dim_a,)\n",
    "        samples weights in the source domain\n",
    "    b : ndarray, shape (dim_b,) or ndarray, shape (dim_b, n_hists)\n",
    "        samples in the target domain, compute sinkhorn with multiple targets\n",
    "        and fixed M if b is a matrix (return OT loss + dual variables in log)\n",
    "    M : ndarray, shape (dim_a, dim_b)\n",
    "        loss matrix\n",
    "    reg : float\n",
    "        Regularization term >0\n",
    "    numItermax : int, optional\n",
    "        Max number of iterations\n",
    "    stopThr : float, optional\n",
    "        Stop threshol on error (>0)\n",
    "    verbose : bool, optional\n",
    "        Print information along iterations\n",
    "    log : bool, optional\n",
    "        record log if True\n",
    "    Returns\n",
    "    -------\n",
    "    gamma : ndarray, shape (dim_a, dim_b)\n",
    "        Optimal transportation matrix for the given parameters\n",
    "    log : dict\n",
    "        log dictionary return only if log==True in parameters\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import ot\n",
    "    >>> a=[.5, .5]\n",
    "    >>> b=[.5, .5]\n",
    "    >>> M=[[0., 1.], [1., 0.]]\n",
    "    >>> ot.sinkhorn(a, b, M, 1)\n",
    "    array([[0.36552929, 0.13447071],\n",
    "           [0.13447071, 0.36552929]])\n",
    "    References\n",
    "    ----------\n",
    "    .. [2] M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013\n",
    "    See Also\n",
    "    --------\n",
    "    ot.lp.emd : Unregularized OT\n",
    "    ot.optim.cg : General regularized OT\n",
    "    \"\"\"\n",
    "\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    b = np.asarray(b, dtype=np.float64)\n",
    "    M = np.asarray(M, dtype=np.float64)\n",
    "\n",
    "    if len(a) == 0:\n",
    "        a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "    if len(b) == 0:\n",
    "        b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    if len(b.shape) > 1:\n",
    "        n_hists = b.shape[1]\n",
    "    else:\n",
    "        n_hists = 0\n",
    "\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if n_hists:\n",
    "        u = np.ones((dim_a, n_hists)) / dim_a\n",
    "        v = np.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u = np.ones(dim_a) / dim_a\n",
    "        v = np.ones(dim_b) / dim_b\n",
    "\n",
    "    # print(reg)\n",
    "\n",
    "    # Next 3 lines equivalent to K= np.exp(-M/reg), but faster to compute\n",
    "    K = np.empty(M.shape, dtype=M.dtype)\n",
    "    np.divide(M, -reg, out=K)\n",
    "    np.exp(K, out=K)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    tmp2 = np.empty(b.shape, dtype=M.dtype)\n",
    "\n",
    "    Kp = (1 / (a+ 1e-299)).reshape(-1, 1) * K\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while (err > stopThr and cpt < numItermax):\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "\n",
    "        KtransposeU = np.dot(K.T, u)\n",
    "        v = np.divide(b, (KtransposeU+ 1e-299))\n",
    "        u = 1. / (np.dot(Kp, v)+ 1e-299)\n",
    "\n",
    "        if (np.any(KtransposeU == 0)\n",
    "                or np.any(np.isnan(u)) or np.any(np.isnan(v))\n",
    "                or np.any(np.isinf(u)) or np.any(np.isinf(v))):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "        if cpt % 10 == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                np.einsum('ik,ij,jk->jk', u, K, v, out=tmp2)\n",
    "            else:\n",
    "                # compute right marginal tmp2= (diag(u)Kdiag(v))^T1\n",
    "                np.einsum('i,ij,j->j', u, K, v, out=tmp2)\n",
    "            err = np.linalg.norm(tmp2 - b)  # violation of marginal\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % 200 == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "        cpt = cpt + 1\n",
    "    if log:\n",
    "        log['u'] = u\n",
    "        log['v'] = v\n",
    "\n",
    "    if n_hists:  # return only loss\n",
    "        res = np.einsum('ik,ij,jk,ij->k', u, K, v, M)\n",
    "        if log:\n",
    "            return res, cpt, log\n",
    "        else:\n",
    "            return res, cpt\n",
    "\n",
    "    else:  # return OT matrix\n",
    "\n",
    "        if log:\n",
    "            return u.reshape((-1, 1)) * K * v.reshape((1, -1)), cpt, log\n",
    "        else:\n",
    "            return u.reshape((-1, 1)) * K * v.reshape((1, -1)), cpt, (np.multiply(M,u.reshape((-1, 1)) * K * v.reshape((1, -1)))).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4                  \n",
    "N = 4\n",
    "m = 0.25*np.ones(M)\n",
    "n = 0.25*np.ones(N)\n",
    "c = np.array([[3.10112791, 2.01924761, 2.        , 2.01924761],\n",
    "     [3.10112791, 3.        , 1.16637984, 1.        ],\n",
    "     [3.        , 3.10112791, 1.16637984, 2.01924761],\n",
    "     [1.        , 3.        , 2.33275967, 4.22075809]])\n",
    "%timeit -r 20 -n 20 sinkhorn_knopp(m,n,c,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: numerical errors at iteration 0\n",
      "78 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.14034157e-05, 2.11001659e-05, 2.07982920e-05, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.11001660e-05, 2.08095516e-05, 2.05200582e-05, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.07982920e-05, 2.05200582e-05, 2.02427037e-05, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [6.41085604e-92, 9.42458775e-92, 1.38531238e-91, ...,\n",
       "         2.02427029e-05, 2.05200574e-05, 2.07982911e-05],\n",
       "        [4.35795298e-92, 6.40918702e-92, 9.42458775e-92, ...,\n",
       "         2.05200574e-05, 2.08095508e-05, 2.11001651e-05],\n",
       "        [2.96202057e-92, 4.35795298e-92, 6.41085604e-92, ...,\n",
       "         2.07982912e-05, 2.11001651e-05, 2.14034148e-05]]),\n",
       " 721,\n",
       " 1.0023757748875959)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0,1,1000)\n",
    "y = np.linspace(1,2,1000)\n",
    "len_x = np.size(x)\n",
    "len_y = np.size(y)\n",
    "\n",
    "c = np.zeros((len_x,len_y))\n",
    "for i in range(len_x):\n",
    "    for j in range(len_y):\n",
    "        c[i,j] = (y[j]-x[i])**2\n",
    "\n",
    "m = np.ones(len_x)/len_x\n",
    "n = np.ones(len_y)/len_y\n",
    "M = len_x\n",
    "N = len_y\n",
    "%timeit -r 1 -n 1 sinkhorn_knopp(m,n,c,0.005)\n",
    "sinkhorn_knopp(m,n,c,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 1 sinkhorn_knopp(m,n,c,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4min 11s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 1 generalised_forward_backward(c,m,n,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6min 53s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 1 primal_dual(c,m,n,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
